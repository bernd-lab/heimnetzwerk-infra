# Cluster Ressourcen-Status und √úbersicht - 2025-11-08

## üìä Node-Status

**Node**: `zuhause`
- **Status**: ‚úÖ Ready
- **OS**: Debian GNU/Linux 12 (bookworm)
- **Kernel**: 6.1.0-40-amd64
- **Kubernetes Version**: v1.34.1
- **Container Runtime**: containerd://1.6.20
- **IP**: 192.168.178.54
- **Uptime**: 6 Tage, 3 Stunden

---

## üíª Ressourcen-Verteilung

### Hardware-Kapazit√§t
- **CPU**: 4 Cores (4000m)
- **Memory**: ~32 GB (32768 Mi)

### Aktuelle Auslastung
- **CPU**: 1315m (32% von 4000m) ‚úÖ **Normal**
- **Memory**: 11571 Mi (36% von 32768 Mi) ‚úÖ **Normal**

### Ressourcen-Requests (garantierte Ressourcen)
- **CPU Requests**: 3950m (98% von 4000m) ‚ö†Ô∏è **KRITISCH - Fast voll**
- **Memory Requests**: 19796 Mi (62% von 32768 Mi) ‚úÖ **OK**

### Ressourcen-Limits (maximale Ressourcen)
- **CPU Limits**: 15400m (385% - Overcommitment) ‚ö†Ô∏è **Hohes Overcommitment**
- **Memory Limits**: 32000 Mi (100%) ‚úÖ **Ausgelastet**

**Warnung**: CPU Requests sind bei 98% - es k√∂nnen keine neuen Pods mit CPU-Requests gestartet werden!

---

## üöÄ Laufende Pods: 45 Pods in 19 Namespaces

### Namespace-Verteilung

| Namespace | Pods | Status |
|-----------|------|--------|
| **kube-system** | 8 | ‚úÖ System-Komponenten |
| **argocd** | 7 | ‚úÖ GitOps |
| **default** | 6 | ‚úÖ Anwendungen |
| **gitlab** | 3 | ‚úÖ GitLab Stack |
| **monitoring** | 3 | ‚úÖ Monitoring |
| **cert-manager** | 3 | ‚úÖ TLS-Zertifikate |
| **metallb-system** | 2 | ‚úÖ LoadBalancer |
| **velero** | 2 | ‚úÖ Backup |
| **gitlab-agent** | 1 | ‚úÖ GitLab Agent |
| **gitlab-runner** | 1 | ‚úÖ CI/CD Runner |
| **heimdall** | 1 | ‚úÖ Dashboard |
| **ingress-nginx** | 1 | ‚úÖ Ingress Controller |
| **komga** | 1 | ‚úÖ Medien-Server |
| **kube-flannel** | 1 | ‚úÖ Netzwerk CNI |
| **kubernetes-dashboard** | 1 | ‚úÖ K8s Dashboard |
| **logging** | 1 | ‚úÖ Logging |
| **pihole** | 1 | ‚úÖ DNS/Ad-Blocker |
| **syncthing** | 1 | ‚úÖ File-Sync |
| **test-tls** | 1 | ‚úÖ Test |

---

## üîß Wichtige Services im Detail

### 1. Pi-hole (DNS/Ad-Blocker)
- **Namespace**: `pihole`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `pihole-85df646787-kqcxj`
- **IP**: 192.168.178.54 (hostNetwork)
- **Ressourcen**: 200m CPU / 256Mi Memory (Requests), 500m CPU / 512Mi Memory (Limits)
- **Blocklisten**: 15 aktive Listen, 1.645.204 blockierte Domains
- **URL**: https://pihole.k8sops.online/admin/

### 2. Jellyfin (Media Server)
- **Namespace**: `default`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `jellyfin-d646478b9-4nvnm`
- **Ressourcen**: 1300m CPU / 10Gi Memory (Requests), 4 CPU / 16Gi Memory (Limits)
- **‚ö†Ô∏è WICHTIG**: Gr√∂√üter CPU/Memory-Verbraucher (32% CPU Requests, 31% Memory Requests)
- **URL**: https://jellyfin.k8sops.online

### 3. GitLab
- **Namespace**: `gitlab`
- **Status**: ‚úÖ Running (3/3 Pods)
- **Pods**: 
  - `gitlab-7b86fcf65b-mz6jt` (GitLab CE)
  - `gitlab-postgresql-0` (PostgreSQL)
  - `gitlab-redis-master-0` (Redis)
- **Ressourcen**: 100m CPU / 4Gi Memory (GitLab), 100m CPU / 256Mi Memory (PostgreSQL), 50m CPU / 128Mi Memory (Redis)
- **URL**: https://gitlab.k8sops.online

### 4. ArgoCD (GitOps)
- **Namespace**: `argocd`
- **Status**: ‚úÖ Running (7/7 Pods)
- **Ressourcen**: 
  - Application Controller: 200m CPU / 512Mi Memory
  - Repo Server: 150m CPU / 512Mi Memory
  - Server: 50m CPU / 256Mi Memory
  - Redis: 50m CPU / 256Mi Memory
  - Dex Server: 50m CPU / 256Mi Memory
  - Notifications Controller: 50m CPU / 256Mi Memory
  - ApplicationSet Controller: keine Limits
- **URL**: https://argocd.k8sops.online

### 5. Monitoring Stack
- **Namespace**: `monitoring`
- **Status**: ‚úÖ Running (3/3 Pods)
- **Pods**: 
  - `prometheus-585d56d988-kgjb5` (Prometheus)
  - `grafana-775b45c697-sh6vk` (Grafana)
  - `grafana-test-85cdf6f69f-hwsrr` (Grafana Test)
- **Ressourcen**: Keine Limits definiert
- **URL**: https://grafana.k8sops.online

### 6. Ingress Controller
- **Namespace**: `ingress-nginx`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `ingress-nginx-controller-68c56f854d-4prxr`
- **IP**: 192.168.178.54 (LoadBalancer)
- **Ressourcen**: 100m CPU / 90Mi Memory (Requests)
- **Ports**: 80:30827/TCP, 443:30941/TCP

### 7. Cert-Manager (TLS-Zertifikate)
- **Namespace**: `cert-manager`
- **Status**: ‚úÖ Running (3/3 Pods)
- **Ressourcen**: 
  - Controller: 100m CPU / 256Mi Memory
  - Webhook: 25m CPU / 128Mi Memory
  - CA Injector: 25m CPU / 128Mi Memory

### 8. Heimdall (Dashboard)
- **Namespace**: `heimdall`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `heimdall-5b7457b589-2bmc6`
- **Ressourcen**: Keine Limits definiert
- **URL**: https://heimdall.k8sops.online

### 9. Komga (Comic-Server)
- **Namespace**: `komga`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `komga-6d8bb46bd5-j4lh9`
- **Ressourcen**: Keine Limits definiert
- **URL**: https://komga.k8sops.online

### 10. Velero (Backup)
- **Namespace**: `velero`
- **Status**: ‚úÖ Running (2/2 Pods)
- **Pods**: 
  - `velero-86b79bd68f-g5tcf` (Velero Controller)
  - `minio-6ff996b598-m2d5h` (MinIO S3 Storage)
- **Ressourcen**: 
  - Velero: 50m CPU / 512Mi Memory (Requests), 1 CPU / 1Gi Memory (Limits)
  - MinIO: 100m CPU / 256Mi Memory (Requests), 500m CPU / 512Mi Memory (Limits)

### 11. Syncthing (File-Sync)
- **Namespace**: `syncthing`
- **Status**: ‚úÖ Running (1/1)
- **Pod**: `syncthing-0` (StatefulSet)
- **Ressourcen**: Keine Limits definiert

### 12. Kubernetes System-Komponenten
- **Namespace**: `kube-system`
- **Status**: ‚úÖ Running (8/8 Pods)
- **Pods**:
  - `etcd-zuhause` (100m CPU / 100Mi Memory)
  - `kube-apiserver-zuhause` (250m CPU)
  - `kube-controller-manager-zuhause` (200m CPU)
  - `kube-scheduler-zuhause` (100m CPU)
  - `kube-proxy-bl2f8` (keine Limits)
  - `coredns-64f644b686-wlcj2` (50m CPU / 128Mi Memory, 500m CPU / 256Mi Memory Limits)
  - `coredns-64f644b686-zbrwn` (50m CPU / 128Mi Memory, 500m CPU / 256Mi Memory Limits)
  - `metrics-server-694c6646d7-clq6x` (50m CPU / 100Mi Memory)

---

## ‚ö†Ô∏è Ressourcen-Probleme

### Kritische Probleme

1. **CPU Requests bei 98%** ‚ö†Ô∏è **KRITISCH**
   - **Aktuell**: 3950m von 4000m belegt
   - **Problem**: Keine neuen Pods mit CPU-Requests k√∂nnen gestartet werden
   - **L√∂sung**: 
     - CPU-Requests f√ºr Pods ohne Limits reduzieren
     - Oder: CPU-Requests f√ºr weniger kritische Pods entfernen
     - Oder: Node erweitern (mehr CPU)

2. **Hohes CPU-Overcommitment (385%)**
   - **Aktuell**: 15400m Limits bei 4000m verf√ºgbar
   - **Problem**: Bei hoher Last k√∂nnen Pods nicht alle Limits gleichzeitig nutzen
   - **Hinweis**: Normal f√ºr Development/Home-Umgebungen, aber sollte √ºberwacht werden

### Potenzielle Probleme

1. **Memory Limits bei 100%**
   - **Aktuell**: 32000 Mi Limits bei ~32768 Mi verf√ºgbar
   - **Problem**: Sehr wenig Puffer f√ºr Memory-Spikes
   - **L√∂sung**: Memory-Limits f√ºr weniger kritische Pods reduzieren

2. **Viele Pods ohne Ressourcen-Limits**
   - **Pods ohne Limits**: plantuml, gitlab-agent, heimdall, komga, syncthing, loki, grafana, prometheus, kubernetes-dashboard, test-nginx
   - **Problem**: K√∂nnen unbegrenzt Ressourcen verbrauchen
   - **Empfehlung**: Limits f√ºr alle Pods definieren

---

## üìà Top Ressourcen-Verbraucher

### CPU Requests (garantierte CPU)
1. **Jellyfin**: 1300m (32% des Nodes)
2. **ArgoCD Application Controller**: 200m (5%)
3. **Pi-hole**: 200m (5%)
4. **Kube API Server**: 250m (6%)
5. **Kube Controller Manager**: 200m (5%)
6. **GitLab**: 100m (2,5%)
7. **Ingress Controller**: 100m (2,5%)
8. **Cert-Manager**: 100m (2,5%)
9. **ArgoCD Repo Server**: 150m (3,75%)
10. **Weitere**: ~1450m (36%)

### Memory Requests (garantierter Memory)
1. **Jellyfin**: 10Gi (31% des Nodes)
2. **GitLab**: 4Gi (12,5%)
3. **ArgoCD Application Controller**: 512Mi (1,6%)
4. **ArgoCD Repo Server**: 512Mi (1,6%)
5. **Velero**: 512Mi (1,6%)
6. **Weitere**: ~4,5Gi (14%)

---

## ‚úÖ Services-Status

### Alle wichtigen Services laufen:
- ‚úÖ **Pi-hole**: DNS/Ad-Blocking funktioniert
- ‚úÖ **Jellyfin**: Media Server l√§uft
- ‚úÖ **GitLab**: Git-Repository l√§uft
- ‚úÖ **ArgoCD**: GitOps funktioniert
- ‚úÖ **Heimdall**: Dashboard verf√ºgbar
- ‚úÖ **Komga**: Comic-Server l√§uft
- ‚úÖ **Grafana**: Monitoring verf√ºgbar
- ‚úÖ **Prometheus**: Metriken werden gesammelt
- ‚úÖ **Ingress Controller**: Routing funktioniert
- ‚úÖ **Cert-Manager**: TLS-Zertifikate werden verwaltet
- ‚úÖ **Velero**: Backup-System l√§uft
- ‚úÖ **Syncthing**: File-Sync l√§uft

### Nicht gestartet:
- ‚ö†Ô∏è **Jenkins**: Deployment vorhanden, aber 0/0 Pods (bewusst deaktiviert)

---

## üîç Empfehlungen

### Sofortige Ma√ünahmen

1. **CPU-Requests reduzieren**:
   - Pods ohne Limits sollten Limits erhalten
   - Weniger kritische Pods sollten CPU-Requests reduzieren
   - Jellyfin k√∂nnte CPU-Requests reduzieren (aktuell 1300m)

2. **Memory-Limits optimieren**:
   - Memory-Limits f√ºr Pods ohne Limits definieren
   - Memory-Limits f√ºr weniger kritische Pods reduzieren

3. **Ressourcen-Limits f√ºr alle Pods definieren**:
   - Besonders wichtig f√ºr: plantuml, gitlab-agent, heimdall, komga, syncthing, loki, grafana, prometheus

### Langfristige Ma√ünahmen

1. **Node erweitern**: Mehr CPU/Memory f√ºr zuk√ºnftige Services
2. **Resource Quotas**: Namespace-basierte Ressourcen-Limits einf√ºhren
3. **Horizontal Pod Autoscaling**: F√ºr Services mit variabler Last
4. **Resource Monitoring**: Grafana-Dashboards f√ºr Ressourcen-√úberwachung

---

## üìä Zusammenfassung

**Status**: ‚úÖ **Cluster l√§uft stabil**

**Ressourcen**:
- ‚úÖ **Aktuelle Auslastung**: Normal (32% CPU, 36% Memory)
- ‚ö†Ô∏è **CPU Requests**: Kritisch (98% belegt)
- ‚ö†Ô∏è **Memory Limits**: Vollst√§ndig ausgelastet (100%)

**Services**: 
- ‚úÖ **45 Pods laufen** in 19 Namespaces
- ‚úÖ **Alle wichtigen Services** sind verf√ºgbar
- ‚ö†Ô∏è **Jenkins** ist deaktiviert (bewusst)

**N√§chste Schritte**:
1. CPU-Requests optimieren (besonders f√ºr Pods ohne Limits)
2. Memory-Limits f√ºr alle Pods definieren
3. Ressourcen-√úberwachung einrichten

---

**Erstellt**: 2025-11-08 19:00 CET  
**Letzte Aktualisierung**: 2025-11-08 19:00 CET

