# Cluster-Vollst√§ndige √úberpr√ºfung

**Datum**: 2025-11-08  
**Status**: ‚úÖ Cluster l√§uft stabil, einige Probleme identifiziert

---

## Phase 1: Zugriff und Grundstatus

### ‚úÖ SSH-Zugriff
- **Status**: ‚úÖ Funktioniert
- **Server**: `zuhause` (192.168.178.54)
- **Uptime**: 22 Stunden
- **Load Average**: 1.35, 2.43, 2.65 (4 CPUs verf√ºgbar)

### ‚úÖ kubectl-Zugriff
- **Status**: ‚úÖ Funktioniert
- **Cluster**: Kubernetes v1.34.1
- **Control Plane**: https://192.168.178.54:6443
- **Node**: `zuhause` - Ready

---

## Phase 2: Pod-Status und Stabilit√§t

### Gesamt-√úbersicht
- **Running**: 47 Pods ‚úÖ
- **Pending**: 0 Pods ‚úÖ
- **CrashLoopBackOff**: 0 Pods ‚úÖ
- **Completed**: 2 Pods (Init-Jobs) ‚úÖ

### Node-Ressourcen
- **CPU Requests**: 3950m (98% von 4000m) ‚ö†Ô∏è **Hoch, aber OK**
- **CPU Limits**: 15400m (385% - Overcommitment)
- **Memory Requests**: 19796Mi (62% von ~32GB) ‚úÖ
- **Memory Limits**: 32000Mi (100%)

### Tats√§chliche Auslastung
- **CPU**: 1255m (31%) ‚úÖ **Gut**
- **Memory**: 11268Mi (35%) ‚úÖ **Gut**

**Hinweis**: Die CPU-Requests sind hoch (98%), aber die tats√§chliche Auslastung ist nur 31%. Das bedeutet, dass die Pods genug Ressourcen haben, aber die Requests k√∂nnten optimiert werden.

### Kritische Services

#### ‚úÖ Pi-hole
- **Namespace**: `pihole`
- **Pod**: `pihole-7fc8889b54-mdl2f` - Running (1/1)
- **Service**: ClusterIP (10.100.79.138)
- **Ports**: 53/TCP, 53/UDP, 80/TCP
- **Status**: ‚úÖ Stabil, keine Restarts

#### ‚úÖ Ingress-Controller
- **Namespace**: `ingress-nginx`
- **Pod**: `ingress-nginx-controller-68c56f854d-bzqbf` - Running (1/1)
- **Status**: ‚úÖ Stabil

#### ‚úÖ Cert-Manager
- **Namespace**: `cert-manager`
- **Pods**: 3 Running (cainjector, cert-manager, webhook)
- **Status**: ‚úÖ Stabil

#### ‚úÖ ArgoCD
- **Namespace**: `argocd`
- **Pods**: 7 Running
  - `argocd-application-controller-0` - Running
  - `argocd-server-76686697fb-jn8cc` - Running
  - `argocd-repo-server-694bc78b6f-ttbxb` - Running
  - `argocd-dex-server-6d457f6565-6lc5p` - Running
  - `argocd-redis-7b6cdf646d-jfvmz` - Running
  - `argocd-notifications-controller-5d5994c6d5-dgjxj` - Running
  - `argocd-applicationset-controller-6fbcc76cf4-g8z44` - Running
- **Status**: ‚ö†Ô∏è **Pod l√§uft, aber Web-Interface nicht erreichbar** (siehe Phase 4)

#### ‚úÖ GitLab
- **Namespace**: `gitlab`
- **Pods**: 3 Running
  - `gitlab-7b86fcf65b-mz6jt` - Running (0 Restarts)
  - `gitlab-postgresql-0` - Running (1 Restart vor 22h)
  - `gitlab-redis-master-0` - Running (1 Restart vor 22h)
- **Status**: ‚úÖ Stabil, Health-Checks funktionieren

---

## Phase 3: Logs-Analyse

### Pi-hole Logs
- **Status**: ‚úÖ Normal
- **Warnungen**: Load Average Warnungen (normal bei hoher Last)
- **Hinweis**: Einige "Cannot get exclusive lock" Warnungen, aber nicht kritisch

### Ingress-Controller Logs
- **Status**: ‚úÖ Normal
- **Hinweis**: GitLab-KAS API-Anfragen (404 ist normal, wenn nicht konfiguriert)

### Cert-Manager Logs
- **Status**: ‚úÖ Normal
- **Hinweis**: Pi-hole Certificate wurde erfolgreich ausgestellt (`pihole-tls`)

### ArgoCD Logs
- **Status**: ‚ö†Ô∏è **Keine Logs verf√ºgbar** (Container-Logs konnten nicht abgerufen werden)
- **Hinweis**: Pod l√§uft, aber m√∂glicherweise Problem mit Log-Zugriff

### GitLab Logs
- **Status**: ‚úÖ Normal
- **Health-Checks**: ‚úÖ Funktionieren (200 OK)
- **Readiness**: ‚úÖ Funktionieren

---

## Phase 4: Webinterfaces

### ‚úÖ Funktionierende Interfaces

| Service | URL | Status | HTTP Code | TLS |
|---------|-----|--------|-----------|-----|
| **GitLab** | https://gitlab.k8sops.online | ‚úÖ | 302 Redirect | ‚úÖ |
| **Jellyfin** | https://jellyfin.k8sops.online | ‚úÖ | 302 Redirect | ‚úÖ |
| **Heimdall** | https://heimdall.k8sops.online | ‚úÖ | 200 OK | ‚úÖ |
| **Grafana** | https://grafana.k8sops.online | ‚úÖ | 302 Redirect | ‚úÖ |
| **Prometheus** | https://prometheus.k8sops.online | ‚úÖ | 405 (Method Not Allowed - normal) | ‚úÖ |
| **Pi-hole** | https://pihole.k8sops.online/admin/ | ‚úÖ | 302 Redirect | ‚úÖ |

### ‚ö†Ô∏è Probleme

#### ArgoCD - Web-Interface nicht erreichbar
- **URL**: https://argocd.k8sops.online
- **Problem**: Timeout bei HTTP-Anfragen
- **Ursache**: Ingress verwendet `backend-protocol: GRPC`, aber HTTP-Requests werden als GRPC behandelt
- **Fehler**: `recv() failed (104: Connection reset by peer) while reading response header from upstream`
- **Status**: ‚ö†Ô∏è **Pod l√§uft, aber Web-Interface nicht erreichbar**

**L√∂sung**: Ingress-Konfiguration √§ndern:
- `nginx.ingress.kubernetes.io/backend-protocol: GRPC` entfernen oder auf `HTTP` √§ndern
- ArgoCD unterst√ºtzt sowohl HTTP als auch GRPC, aber f√ºr das Web-Interface sollte HTTP verwendet werden

---

## Phase 5: DNS-Tests

### ‚úÖ DNS-Aufl√∂sung
- **Von WSL2 aus**: ‚úÖ `argocd.k8sops.online` ‚Üí `192.168.178.54`
- **Von WSL2 aus**: ‚úÖ `gitlab.k8sops.online` ‚Üí `192.168.178.54`
- **Pi-hole DNS**: ‚úÖ `dig @192.168.178.54 google.de` funktioniert

### ‚ö†Ô∏è DNS-Problem bei curl
- **Problem**: `curl` von WSL2 aus kann Domains nicht aufl√∂sen (Timeout)
- **Ursache**: WSL2-Netzwerk-Isolation (bekanntes Problem)
- **Workaround**: DNS-Aufl√∂sung funktioniert mit `dig`, aber nicht mit `curl`
- **L√∂sung**: Tests vom Server selbst durchf√ºhren (funktioniert)

### DNS-Konfiguration
- **Pi-hole**: ‚úÖ L√§uft auf Port 53 (Host-Netzwerk)
- **CoreDNS**: ‚úÖ Forward an Pi-hole konfiguriert
- **FritzBox**: ‚ö†Ô∏è **Nicht getestet** (sollte auf `192.168.178.54` zeigen)

---

## Phase 6: Ingress und Netzwerk-Konfiguration

### Ingress-Controller
- **Status**: ‚úÖ Running
- **LoadBalancer IP**: `192.168.178.54`
- **Host Network**: `true` (bindet direkt an Host-IP)
- **Ports**: 80 (HTTP), 443 (HTTPS)

### Ingress-Ressourcen (13)
Alle Ingress-Ressourcen sind konfiguriert:
- ‚úÖ ArgoCD (aber mit GRPC-Problem)
- ‚úÖ GitLab
- ‚úÖ Jellyfin
- ‚úÖ Heimdall
- ‚úÖ Grafana
- ‚úÖ Prometheus
- ‚úÖ Pi-hole
- ‚úÖ Jenkins
- ‚úÖ Komga
- ‚úÖ Loki
- ‚úÖ Syncthing
- ‚úÖ Kubernetes Dashboard
- ‚úÖ PlantUML
- ‚úÖ Test

### TLS-Zertifikate
- **Status**: ‚úÖ Alle Zertifikate sind g√ºltig (au√üer Pi-hole)
- **Pi-hole**: ‚ö†Ô∏è **Zwei Certificates**:
  - `pihole-k8sops-online-tls`: READY=False (zeigt auf `pihole-tls` Secret)
  - `pihole-tls`: READY=True
- **Problem**: Beide Certificates zeigen auf dasselbe Secret (`pihole-tls`)
- **L√∂sung**: Altes Certificate (`pihole-tls`) l√∂schen, nur `pihole-k8sops-online-tls` behalten

---

## Phase 7: FritzBox-Konfiguration

### ‚ö†Ô∏è Nicht getestet
- **DNS-Server**: Sollte auf `192.168.178.54` zeigen
- **Status**: ‚ö†Ô∏è **Muss manuell gepr√ºft werden**

---

## Identifizierte Probleme

### P1 - Wichtig (Bald beheben)

1. **ArgoCD Web-Interface nicht erreichbar**
   - **Problem**: Ingress verwendet GRPC, aber HTTP-Requests kommen an
   - **L√∂sung**: Ingress-Konfiguration √§ndern (`backend-protocol: HTTP` statt `GRPC`)
   - **Datei**: Ingress-Ressource `argocd-ingress` im Namespace `argocd`

2. **Pi-hole Certificate-Konflikt**
   - **Problem**: Zwei Certificates zeigen auf dasselbe Secret
   - **L√∂sung**: Altes Certificate (`pihole-tls`) l√∂schen
   - **Befehl**: `kubectl delete certificate -n pihole pihole-tls`

### P2 - Beobachten

3. **CPU-Requests hoch (98%)**
   - **Problem**: CPU-Requests sind bei 98%, aber tats√§chliche Auslastung nur 31%
   - **Auswirkung**: Keine kritische Auswirkung, aber k√∂nnte optimiert werden
   - **L√∂sung**: CPU-Requests f√ºr weniger kritische Services reduzieren

4. **WSL2-Netzwerk-Isolation**
   - **Problem**: DNS-Aufl√∂sung funktioniert mit `dig`, aber nicht mit `curl`
   - **Auswirkung**: Tests m√ºssen vom Server selbst durchgef√ºhrt werden
   - **Status**: Bekanntes Problem, kein kritischer Fehler

---

## Zusammenfassung

### ‚úÖ Funktioniert
- SSH-Zugriff
- kubectl-Zugriff
- Alle Pods laufen stabil
- GitLab Web-Interface
- Jellyfin Web-Interface
- Heimdall Web-Interface
- Grafana Web-Interface
- Prometheus Web-Interface
- Pi-hole DNS-Server
- DNS-Aufl√∂sung (mit dig)
- TLS-Zertifikate (au√üer Pi-hole-Konflikt)

### ‚ö†Ô∏è Probleme
- ArgoCD Web-Interface nicht erreichbar (GRPC-Konfiguration)
- Pi-hole Certificate-Konflikt (zwei Certificates)
- FritzBox-Konfiguration nicht getestet

### üìã N√§chste Schritte

1. **ArgoCD Ingress reparieren**:
   ```bash
   kubectl annotate ingress argocd-ingress -n argocd \
     nginx.ingress.kubernetes.io/backend-protocol=HTTP \
     --overwrite
   ```

2. **Pi-hole Certificate bereinigen**:
   ```bash
   kubectl delete certificate -n pihole pihole-tls
   ```

3. **FritzBox DNS-Konfiguration pr√ºfen**:
   - DNS-Server sollte auf `192.168.178.54` zeigen
   - Von verschiedenen Ger√§ten im Heimnetzwerk testen

4. **CPU-Requests optimieren** (optional):
   - Weniger kritische Services analysieren
   - CPU-Requests reduzieren wo m√∂glich

---

**Ende des Reports**

